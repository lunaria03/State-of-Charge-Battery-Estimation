{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Library\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "from sklearn.svm import SVR\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "#File That We Will Use\n",
    "train_names = [ \n",
    "        \n",
    "        '10degC/752_Mixed1', \n",
    "        '10degC/752_Mixed2',\n",
    "        '10degC/756_Mixed3', \n",
    "        '10degC/756_Mixed4',\n",
    "        '10degC/756_Mixed5', \n",
    "        '10degC/756_Mixed6',\n",
    "        '10degC/756_Mixed7',\n",
    "        '10degC/756_Mixed8',\n",
    "\n",
    "        '25degC/734_Mixed1', \n",
    "        '25degC/734_Mixed2', \n",
    "        '25degC/740_Mixed3',\n",
    "        '25degC/740_Mixed4',\n",
    "        '25degC/740_Mixed5',\n",
    "        '25degC/740_Mixed6',\n",
    "        '25degC/740_Mixed7', \n",
    "        '25degC/740_Mixed8', \n",
    "\n",
    "        '40degC/710_Mixed1',\n",
    "        '40degC/710_Mixed2',\n",
    "        '40degC/722_Mixed3',\n",
    "        '40degC/722_Mixed4', \n",
    "        '40degC/722_Mixed5',\n",
    "        '40degC/722_Mixed6',\n",
    "        '40degC/722_Mixed7',\n",
    "        '40degC/722_Mixed8',\n",
    "        \n",
    "        ]\n",
    "\n",
    "test_names = [\n",
    "\n",
    "        '10degC/752_LA92'\n",
    "        '10degC/752_UDDS'\n",
    "\n",
    "        '25degC/734_LA92'\n",
    "        '25degC/734_UDDS'\n",
    "        \n",
    "        '40degC/710_LA92'\n",
    "        '40degC/710_UDDS'\n",
    "\n",
    "        ]\n",
    "\n",
    "path = 'C:/Kuliah/Skripsi/Dataset/Samsung INR21700 30T/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Applied 3 Other Function into the Dataset\n",
    "def get_discharge_whole_cycle(train_names, test_names, scale_test=False):\n",
    "        train = _get_data(train_names)\n",
    "        test = _get_data(test_names)\n",
    "        train, test = _scale_x(train, test, scale_test=scale_test)        \n",
    "        return (train, test)\n",
    "\n",
    "# Function to Choose X and Y\n",
    "def _get_data(names):\n",
    "        cycles = []\n",
    "        for name in names:\n",
    "            cycle = pd.read_csv(path + name + '.csv', skiprows=30)\n",
    "            cycle.columns = ['Time Stamp','Step','Status','Prog Time','Step Time','Cycle',\n",
    "                            'Cycle Level','Procedure','Voltage','Current','Temperature','Capacity','WhAccu','Cnt','Empty']\n",
    "            cycle = cycle[(cycle[\"Status\"] == \"TABLE\") | (cycle[\"Status\"] == \"DCH\")]\n",
    "\n",
    "            max_discharge = abs(min(cycle[\"Capacity\"]))\n",
    "            cycle[\"SoC Capacity\"] = max_discharge + cycle[\"Capacity\"]\n",
    "            cycle[\"SoC Percentage\"] = cycle[\"SoC Capacity\"] / max(cycle[\"SoC Capacity\"])\n",
    "\n",
    "            cycle['Prog Time'] = cycle['Prog Time'].apply(_time_string_to_seconds)\n",
    "            cycle['Time in Seconds'] = cycle['Prog Time'] - cycle['Prog Time'][0]\n",
    "            cycle['Time in Seconds'] = cycle['Time in Seconds'].round()\n",
    "\n",
    "            cycle_per_second = cycle.groupby('Time in Seconds').agg({\n",
    "                'Voltage': 'mean',\n",
    "                'Current': 'mean',\n",
    "                'Temperature': 'mean',\n",
    "                'SoC Percentage': 'mean'  \n",
    "            }).reset_index()\n",
    "\n",
    "            x = cycle_per_second[[\"Voltage\", \"Current\", \"Temperature\"]].to_numpy()\n",
    "            y = cycle_per_second[[\"SoC Percentage\"]].to_numpy()\n",
    "\n",
    "            cycles.append((x, y))\n",
    "\n",
    "        return cycles\n",
    "\n",
    "# Function to Transform Time Sampling into Seconds\n",
    "def _time_string_to_seconds(input_string):\n",
    "    time_parts = input_string.split(':')\n",
    "    second_parts = time_parts[2].split('.')\n",
    "    return timedelta(hours=int(time_parts[0]), \n",
    "        minutes=int(time_parts[1]), \n",
    "        seconds=int(second_parts[0]), \n",
    "        microseconds=int(second_parts[1])).total_seconds()\n",
    "\n",
    "# Function to Normalize Dataset\n",
    "def _scale_x(train, test, scale_test=False):\n",
    "    for index_feature in range(len(train[0][0][0])):\n",
    "        feature_min = min([min(cycle[0][:,index_feature]) for cycle in train])\n",
    "        feature_max = max([max(cycle[0][:,index_feature]) for cycle in train])\n",
    "        for i in range(len(train)):\n",
    "            train[i][0][:,index_feature] = (train[i][0][:,index_feature]-feature_min)/(feature_max-feature_min)\n",
    "        if scale_test:\n",
    "            for i in range(len(test)):\n",
    "                test[i][0][:,index_feature] = (test[i][0][:,index_feature]-feature_min)/(feature_max-feature_min)\n",
    "\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying Every Function to Dataset That We Use\n",
    "cycles = get_discharge_whole_cycle(train_names, test_names, scale_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting cycles into train and test sets\n",
    "train_cycles, test_cycles = cycles\n",
    "train_x = np.concatenate([x for x, _ in train_cycles])\n",
    "train_y = np.concatenate([y for _, y in train_cycles]).ravel()  # Convert to 1D array\n",
    "test_x = np.concatenate([x for x, _ in test_cycles])\n",
    "test_y = np.concatenate([y for _, y in test_cycles]).ravel()  # Convert to 1D array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting into Train and Validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_x, train_y, test_size=0.2, random_state=0,shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train SVR model\n",
    "svr_model = SVR(kernel='rbf', C=100, gamma=0.125) \n",
    "svr_model.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "joblib.dump(svr_model, 'svm_model8.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict test_y\n",
    "predicted_test_y = svr_model.predict(test_x)\n",
    "\n",
    "# Plotting predictions vs actual data\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(test_y, label='Actual')\n",
    "plt.plot(predicted_test_y, label='Predicted')\n",
    "plt.title('SVR RBF Kernel: Predicted vs Actual')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('SoC Percentage')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = np.sqrt(mean_squared_error(test_y, predicted_test_y))\n",
    "print(\"RMSE:\", rmse)\n",
    "\n",
    "# Calculate MAE\n",
    "mae = mean_absolute_error(test_y, predicted_test_y)\n",
    "print(\"MAE:\", mae)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
