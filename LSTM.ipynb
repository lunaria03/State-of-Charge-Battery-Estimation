{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Library \n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "#File That We Will Use\n",
    "train_names = [ \n",
    "        \n",
    "        '10degC/752_Mixed1', \n",
    "        '10degC/752_Mixed2',\n",
    "        '10degC/756_Mixed3', \n",
    "        '10degC/756_Mixed4',\n",
    "        '10degC/756_Mixed5', \n",
    "        '10degC/756_Mixed6',\n",
    "        '10degC/756_Mixed7',\n",
    "        '10degC/756_Mixed8',\n",
    "\n",
    "        '25degC/734_Mixed1', \n",
    "        '25degC/734_Mixed2', \n",
    "        '25degC/740_Mixed3',\n",
    "        '25degC/740_Mixed4',\n",
    "        '25degC/740_Mixed5',\n",
    "        '25degC/740_Mixed6',\n",
    "        '25degC/740_Mixed7', \n",
    "        '25degC/740_Mixed8', \n",
    "\n",
    "        '40degC/710_Mixed1',\n",
    "        '40degC/710_Mixed2',\n",
    "        '40degC/722_Mixed3',\n",
    "        '40degC/722_Mixed4', \n",
    "        '40degC/722_Mixed5',\n",
    "        '40degC/722_Mixed6',\n",
    "        '40degC/722_Mixed7',\n",
    "        '40degC/722_Mixed8',\n",
    "        \n",
    "        ]\n",
    "\n",
    "test_names = [\n",
    "\n",
    "        '10degC/752_LA92'\n",
    "        '10degC/752_UDDS'\n",
    "\n",
    "        '25degC/734_LA92'\n",
    "        '25degC/734_UDDS'\n",
    "        \n",
    "        '40degC/710_LA92'\n",
    "        '40degC/710_UDDS'\n",
    "\n",
    "        ]\n",
    "\n",
    "path = 'C:/Kuliah/Skripsi/Dataset/Samsung INR21700 30T/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Applied 3 Other Function into the Dataset\n",
    "def get_discharge_whole_cycle(train_names, test_names, scale_test=False):\n",
    "        train = _get_data(train_names)\n",
    "        test = _get_data(test_names)\n",
    "        train, test = _scale_x(train, test, scale_test=scale_test)        \n",
    "        return (train, test)\n",
    "\n",
    "# Function to Choose X and Y\n",
    "def _get_data(names):\n",
    "        cycles = []\n",
    "        for name in names:\n",
    "            cycle = pd.read_csv(path + name + '.csv', skiprows=30)\n",
    "            cycle.columns = ['Time Stamp','Step','Status','Prog Time','Step Time','Cycle',\n",
    "                            'Cycle Level','Procedure','Voltage','Current','Temperature','Capacity','WhAccu','Cnt','Empty']\n",
    "            cycle = cycle[(cycle[\"Status\"] == \"TABLE\") | (cycle[\"Status\"] == \"DCH\")]\n",
    "\n",
    "            max_discharge = abs(min(cycle[\"Capacity\"]))\n",
    "            cycle[\"SoC Capacity\"] = max_discharge + cycle[\"Capacity\"]\n",
    "            cycle[\"SoC Percentage\"] = cycle[\"SoC Capacity\"] / max(cycle[\"SoC Capacity\"])\n",
    "\n",
    "            cycle['Prog Time'] = cycle['Prog Time'].apply(_time_string_to_seconds)\n",
    "            cycle['Time in Seconds'] = cycle['Prog Time'] - cycle['Prog Time'][0]\n",
    "            cycle['Time in Seconds'] = cycle['Time in Seconds'].round()\n",
    "\n",
    "            cycle_per_second = cycle.groupby('Time in Seconds').agg({\n",
    "                'Voltage': 'mean',\n",
    "                'Current': 'mean',\n",
    "                'Temperature': 'mean',\n",
    "                'SoC Percentage': 'mean',\n",
    "            }).reset_index()\n",
    "\n",
    "            x = cycle_per_second[[\"Voltage\", \"Current\", \"Temperature\"]].to_numpy()\n",
    "            y = cycle_per_second[[\"SoC Percentage\"]].to_numpy()\n",
    "\n",
    "            cycles.append((x, y))\n",
    "\n",
    "        return cycles\n",
    "\n",
    "# Function to Transform Time Sampling into Seconds\n",
    "def _time_string_to_seconds(input_string):\n",
    "    time_parts = input_string.split(':')\n",
    "    second_parts = time_parts[2].split('.')\n",
    "    return timedelta(hours=int(time_parts[0]), \n",
    "        minutes=int(time_parts[1]), \n",
    "        seconds=int(second_parts[0]), \n",
    "        microseconds=int(second_parts[1])).total_seconds()\n",
    "\n",
    "# Function to Normalize Dataset\n",
    "def _scale_x(train, test, scale_test=False):\n",
    "    for index_feature in range(len(train[0][0][0])):\n",
    "        feature_min = min([min(cycle[0][:,index_feature]) for cycle in train])\n",
    "        feature_max = max([max(cycle[0][:,index_feature]) for cycle in train])\n",
    "        for i in range(len(train)):\n",
    "            train[i][0][:,index_feature] = (train[i][0][:,index_feature]-feature_min)/(feature_max-feature_min)\n",
    "        if scale_test:\n",
    "            for i in range(len(test)):\n",
    "                test[i][0][:,index_feature] = (test[i][0][:,index_feature]-feature_min)/(feature_max-feature_min)\n",
    "\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying Every Function to Dataset That We Use\n",
    "cycles = get_discharge_whole_cycle(train_names, test_names, scale_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define window size\n",
    "window_size = 20\n",
    "\n",
    "# Function to create windowed dataset\n",
    "def create_windowed_dataset(input_data, target_data, window_size):\n",
    "    X, y = [], []\n",
    "    for i in range(len(input_data) - window_size):\n",
    "        X.append(input_data[i:i+window_size])\n",
    "        y.append(target_data[i+window_size])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Create windowed dataset for training data\n",
    "X_train, y_train = [], []\n",
    "for input_data, target_data in cycles[0]:  \n",
    "    X, y = create_windowed_dataset(input_data, target_data, window_size)\n",
    "    X_train.append(X)\n",
    "    y_train.append(y)\n",
    "X_train, y_train = np.concatenate(X_train), np.concatenate(y_train)\n",
    "\n",
    "# Reshape data for LSTM\n",
    "X_train = X_train.reshape(X_train.shape[0], window_size, X_train.shape[2])\n",
    "\n",
    "# Create windowed dataset for testing data\n",
    "X_test, y_test = [], []\n",
    "for input_data, target_data in cycles[1]:  # Assuming cycles[1] contains testing data\n",
    "    X, y = create_windowed_dataset(input_data, target_data, window_size)\n",
    "    X_test.append(X)\n",
    "    y_test.append(y)\n",
    "X_test, y_test = np.concatenate(X_test), np.concatenate(y_test)\n",
    "\n",
    "# Reshape data for LSTM\n",
    "X_test = X_test.reshape(X_test.shape[0], window_size, X_test.shape[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LSTM Model\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.00001)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, return_sequences=False, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dense(32))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer=opt, loss='huber', metrics=['mae', tf.keras.metrics.RootMeanSquaredError(name='rmse')])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['mae'], label='Training MAE')\n",
    "plt.plot(history.history['val_mae'], label='Validation MAE')\n",
    "plt.title('Training and Validation MAE')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MAE')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['rmse'], label='Training RMSE')\n",
    "plt.plot(history.history['val_rmse'], label='Validation RMSE')\n",
    "plt.title('Training and Validation RMSE')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('RMSE')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "model.save(\"lstm_model2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(y_pred.flatten(), label='SoC Predicted', color='blue')\n",
    "plt.plot(y_test.flatten(), label='SoC Actual', color='red')\n",
    "plt.title('LSTM Predictions vs Actual Values on 40C US06')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('SoC Percentage')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"RMSE:\", rmse)\n",
    "\n",
    "# Calculate MAE\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(\"MAE:\", mae)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
